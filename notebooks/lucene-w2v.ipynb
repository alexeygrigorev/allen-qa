{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs \n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = []\n",
    "with codecs.open('/home/agrigorev/git-projects/allen-qa/lucene-features-3.json', 'r', 'utf-8') as f:\n",
    "    for line in f:\n",
    "        dicts.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = pd.DataFrame(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'answer', u'answerLetter', u'ck12EbookAnswerResult', u'ck12EbookBothQADoc', u'ck12EbookBothQADocAMustHave', u'ck12EbookBothQADocCount', u'ck12EbookBothQADocCountAMustHave', u'ck12EbookKendallTauCorr', u'ck12EbookQuestionResult', u'ck12EbookSpearmanCorr', u'ck12WikiAnswerResult', u'ck12WikiBothQADoc', u'ck12WikiBothQADocAMustHave', u'ck12WikiBothQADocCount', u'ck12WikiBothQADocCountAMustHave', u'ck12WikiKendallTauCorr', u'ck12WikiQuestionResult', u'ck12WikiSpearmanCorr', u'label', u'ngramsAnswer', u'ngramsCk12EbookAnswerResult', u'ngramsCk12EbookBothQADoc', u'ngramsCk12EbookBothQADocCount', u'ngramsCk12EbookBothQADocCountAMustHave', u'ngramsCk12EbookBothQADocMustHave', u'ngramsCk12EbookKendallTauCorr', u'ngramsCk12EbookQuestionResult', u'ngramsCk12EbookSpearmanCorr', u'ngramsCk12WikiAnswerResult', u'ngramsCk12WikiBothQADoc', u'ngramsCk12WikiBothQADocCount', u'ngramsCk12WikiBothQADocCountAMustHave', u'ngramsCk12WikiBothQADocMustHave', u'ngramsCk12WikiKendallTauCorr', u'ngramsCk12WikiQuestionResult', u'ngramsCk12WikiSpearmanCorr', u'ngramsQuestion', u'question', u'questionId', u'rawAnswer', u'rawQuestion', u'source', u'type', u'word2vecAnswer', u'word2vecCosine', u'word2vecMissing', u'word2vecQuestion'], dtype='object')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_doc_features(docs):\n",
    "    top = docs[:3]\n",
    "    names = [d['title'] for d in top]\n",
    "    all_scores = [d['score'] for d in docs]\n",
    "    if not all_scores:\n",
    "        all_scores = [0]\n",
    "\n",
    "    top_scores = [d['score'] for d in top]\n",
    "    if not top_scores:\n",
    "        top_scores = [0]\n",
    "\n",
    "    median_score = np.median(all_scores)\n",
    "    mean_score = np.mean(all_scores)\n",
    "    min_score = np.min(all_scores)\n",
    "\n",
    "    score_1 = np.max(top_scores)\n",
    "    score_2 = np.median(top_scores)\n",
    "    score_3 = np.min(top_scores)\n",
    "\n",
    "    return pd.Series((names, median_score, mean_score, min_score, score_1, score_2, score_3))\n",
    "\n",
    "def names(pref):\n",
    "    res = ['names', 'median_score', 'mean_score', 'min_score', 'score_1', 'score_2', 'score_3']\n",
    "    return [pref + '_' + n for n in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('ck_12_answer')] = questions.ck12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_question')] = questions.ck12EbookQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions[names('wiki_answer')] = questions.ck12WikiAnswerResult.apply(extract_doc_features)\n",
    "questions[names('wiki_question')] = questions.ck12WikiQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('ck_12_ngram_answer')] = questions.ngramsCk12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_ngram_question')] = questions.ngramsCk12EbookQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('wiki_ngram_answer')] = questions.ngramsCk12WikiAnswerResult.apply(extract_doc_features)\n",
    "questions[names('wiki_ngram_question')] = questions.ngramsCk12WikiQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions.word2vecAnswer = questions.word2vecAnswer.apply(lambda x: np.array(x).astype('float'))\n",
    "questions.word2vecQuestion = questions.word2vecQuestion.apply(lambda x: np.array(x).astype('float'))\n",
    "questions.word2vecCosine = questions.word2vecCosine.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NaNs_to_zeros(vec):\n",
    "    if np.isnan(vec).all():\n",
    "        return np.zeros_like(vec)\n",
    "    else:\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions.word2vecAnswer = questions.word2vecAnswer.apply(NaNs_to_zeros)\n",
    "questions.word2vecQuestion = questions.word2vecQuestion.apply(NaNs_to_zeros)\n",
    "questions.word2vecCosine[questions.word2vecCosine.isnull()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = questions[questions.source == 'TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ck12EbookBothQADocCount',\n",
       " u'ck12EbookBothQADocCountAMustHave',\n",
       " u'ck12EbookKendallTauCorr',\n",
       " u'ck12EbookSpearmanCorr',\n",
       " u'ck12WikiBothQADocCount',\n",
       " u'ck12WikiBothQADocCountAMustHave',\n",
       " u'ck12WikiKendallTauCorr',\n",
       " u'ck12WikiSpearmanCorr',\n",
       " u'ngramsCk12EbookBothQADocCount',\n",
       " u'ngramsCk12EbookBothQADocCountAMustHave',\n",
       " u'ngramsCk12EbookKendallTauCorr',\n",
       " u'ngramsCk12EbookSpearmanCorr',\n",
       " u'ngramsCk12WikiBothQADocCount',\n",
       " u'ngramsCk12WikiBothQADocCountAMustHave',\n",
       " u'ngramsCk12WikiKendallTauCorr',\n",
       " u'ngramsCk12WikiSpearmanCorr',\n",
       " u'word2vecCosine',\n",
       " u'word2vecMissing',\n",
       " 'ck_12_answer_median_score',\n",
       " 'ck_12_answer_mean_score',\n",
       " 'ck_12_answer_min_score',\n",
       " 'ck_12_answer_score_1',\n",
       " 'ck_12_answer_score_2',\n",
       " 'ck_12_answer_score_3',\n",
       " 'ck_12_question_median_score',\n",
       " 'ck_12_question_mean_score',\n",
       " 'ck_12_question_min_score',\n",
       " 'ck_12_question_score_1',\n",
       " 'ck_12_question_score_2',\n",
       " 'ck_12_question_score_3',\n",
       " 'wiki_answer_median_score',\n",
       " 'wiki_answer_mean_score',\n",
       " 'wiki_answer_min_score',\n",
       " 'wiki_answer_score_1',\n",
       " 'wiki_answer_score_2',\n",
       " 'wiki_answer_score_3',\n",
       " 'wiki_question_median_score',\n",
       " 'wiki_question_mean_score',\n",
       " 'wiki_question_min_score',\n",
       " 'wiki_question_score_1',\n",
       " 'wiki_question_score_2',\n",
       " 'wiki_question_score_3',\n",
       " 'ck_12_ngram_answer_median_score',\n",
       " 'ck_12_ngram_answer_mean_score',\n",
       " 'ck_12_ngram_answer_min_score',\n",
       " 'ck_12_ngram_answer_score_1',\n",
       " 'ck_12_ngram_answer_score_2',\n",
       " 'ck_12_ngram_answer_score_3',\n",
       " 'ck_12_ngram_question_median_score',\n",
       " 'ck_12_ngram_question_mean_score',\n",
       " 'ck_12_ngram_question_min_score',\n",
       " 'ck_12_ngram_question_score_1',\n",
       " 'ck_12_ngram_question_score_2',\n",
       " 'ck_12_ngram_question_score_3',\n",
       " 'wiki_ngram_answer_median_score',\n",
       " 'wiki_ngram_answer_mean_score',\n",
       " 'wiki_ngram_answer_min_score',\n",
       " 'wiki_ngram_answer_score_1',\n",
       " 'wiki_ngram_answer_score_2',\n",
       " 'wiki_ngram_answer_score_3',\n",
       " 'wiki_ngram_question_median_score',\n",
       " 'wiki_ngram_question_mean_score',\n",
       " 'wiki_ngram_question_min_score',\n",
       " 'wiki_ngram_question_score_1',\n",
       " 'wiki_ngram_question_score_2',\n",
       " 'wiki_ngram_question_score_3']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = train._get_numeric_data()\n",
    "benchmark_features = list(num.columns)\n",
    "benchmark_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for id, group in train.groupby('questionId'):\n",
    "    row = {}\n",
    "    row['correct'] = (group.label == 'true').values.argmax()\n",
    "\n",
    "    for f in benchmark_features:\n",
    "        row[f] = group[f].values.argmax()\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>                         word2vecCosine</td>\n",
       "      <td> 0.3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>                   ck_12_answer_score_3</td>\n",
       "      <td> 0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>             ck_12_ngram_answer_score_2</td>\n",
       "      <td> 0.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>          ck_12_ngram_answer_mean_score</td>\n",
       "      <td> 0.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>             ck_12_ngram_answer_score_1</td>\n",
       "      <td> 0.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>             ck_12_ngram_answer_score_3</td>\n",
       "      <td> 0.2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>                   ck_12_answer_score_2</td>\n",
       "      <td> 0.2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>        ck_12_ngram_answer_median_score</td>\n",
       "      <td> 0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>              ck_12_answer_median_score</td>\n",
       "      <td> 0.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>                 ck_12_answer_min_score</td>\n",
       "      <td> 0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>                ck_12_answer_mean_score</td>\n",
       "      <td> 0.2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>  ngramsCk12WikiBothQADocCountAMustHave</td>\n",
       "      <td> 0.2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>                   ck_12_answer_score_1</td>\n",
       "      <td> 0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>           ck_12_ngram_answer_min_score</td>\n",
       "      <td> 0.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> ngramsCk12EbookBothQADocCountAMustHave</td>\n",
       "      <td> 0.2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>       ck12EbookBothQADocCountAMustHave</td>\n",
       "      <td> 0.2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>                  wiki_answer_min_score</td>\n",
       "      <td> 0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>        ck12WikiBothQADocCountAMustHave</td>\n",
       "      <td> 0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>                    wiki_answer_score_2</td>\n",
       "      <td> 0.2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>                    wiki_answer_score_1</td>\n",
       "      <td> 0.2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>           ngramsCk12WikiBothQADocCount</td>\n",
       "      <td> 0.2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>                    wiki_answer_score_3</td>\n",
       "      <td> 0.2656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>                 wiki_answer_mean_score</td>\n",
       "      <td> 0.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>               wiki_answer_median_score</td>\n",
       "      <td> 0.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>                  ck12EbookSpearmanCorr</td>\n",
       "      <td> 0.2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>                ck12EbookBothQADocCount</td>\n",
       "      <td> 0.2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>                ck12EbookKendallTauCorr</td>\n",
       "      <td> 0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>                 ck12WikiBothQADocCount</td>\n",
       "      <td> 0.2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>                   ck12WikiSpearmanCorr</td>\n",
       "      <td> 0.2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>          ngramsCk12EbookBothQADocCount</td>\n",
       "      <td> 0.2576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>                 ck12WikiKendallTauCorr</td>\n",
       "      <td> 0.2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>          ngramsCk12EbookKendallTauCorr</td>\n",
       "      <td> 0.2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>            ngramsCk12EbookSpearmanCorr</td>\n",
       "      <td> 0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>                        word2vecMissing</td>\n",
       "      <td> 0.2384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>                  wiki_question_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>              wiki_ngram_answer_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>              wiki_ngram_answer_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>             ngramsCk12WikiSpearmanCorr</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>           ngramsCk12WikiKendallTauCorr</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>       wiki_ngram_question_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>              wiki_ngram_answer_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>                wiki_question_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>         wiki_ngram_question_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>          wiki_ngram_question_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>            wiki_ngram_question_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>            wiki_ngram_answer_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>           wiki_ngram_answer_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>         wiki_ngram_answer_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>         ck_12_ngram_question_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>               wiki_question_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>             wiki_question_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>                  wiki_question_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>                  wiki_question_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>      ck_12_ngram_question_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>            wiki_ngram_question_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>        ck_12_ngram_question_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>                 ck_12_question_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>           ck_12_ngram_question_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>                 ck_12_question_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>                 ck_12_question_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   feature  accuracy\n",
       "16                          word2vecCosine    0.3156\n",
       "23                    ck_12_answer_score_3    0.2976\n",
       "46              ck_12_ngram_answer_score_2    0.2920\n",
       "43           ck_12_ngram_answer_mean_score    0.2864\n",
       "45              ck_12_ngram_answer_score_1    0.2864\n",
       "47              ck_12_ngram_answer_score_3    0.2856\n",
       "22                    ck_12_answer_score_2    0.2856\n",
       "42         ck_12_ngram_answer_median_score    0.2836\n",
       "18               ck_12_answer_median_score    0.2800\n",
       "20                  ck_12_answer_min_score    0.2784\n",
       "19                 ck_12_answer_mean_score    0.2764\n",
       "13   ngramsCk12WikiBothQADocCountAMustHave    0.2760\n",
       "21                    ck_12_answer_score_1    0.2748\n",
       "44            ck_12_ngram_answer_min_score    0.2740\n",
       "9   ngramsCk12EbookBothQADocCountAMustHave    0.2728\n",
       "1         ck12EbookBothQADocCountAMustHave    0.2724\n",
       "32                   wiki_answer_min_score    0.2700\n",
       "5          ck12WikiBothQADocCountAMustHave    0.2700\n",
       "34                     wiki_answer_score_2    0.2684\n",
       "33                     wiki_answer_score_1    0.2668\n",
       "12            ngramsCk12WikiBothQADocCount    0.2664\n",
       "35                     wiki_answer_score_3    0.2656\n",
       "31                  wiki_answer_mean_score    0.2644\n",
       "30                wiki_answer_median_score    0.2624\n",
       "3                    ck12EbookSpearmanCorr    0.2612\n",
       "0                  ck12EbookBothQADocCount    0.2612\n",
       "2                  ck12EbookKendallTauCorr    0.2600\n",
       "4                   ck12WikiBothQADocCount    0.2592\n",
       "7                     ck12WikiSpearmanCorr    0.2584\n",
       "8            ngramsCk12EbookBothQADocCount    0.2576\n",
       "6                   ck12WikiKendallTauCorr    0.2544\n",
       "10           ngramsCk12EbookKendallTauCorr    0.2532\n",
       "11             ngramsCk12EbookSpearmanCorr    0.2500\n",
       "17                         word2vecMissing    0.2384\n",
       "39                   wiki_question_score_1    0.2336\n",
       "58               wiki_ngram_answer_score_2    0.2336\n",
       "57               wiki_ngram_answer_score_1    0.2336\n",
       "15              ngramsCk12WikiSpearmanCorr    0.2336\n",
       "14            ngramsCk12WikiKendallTauCorr    0.2336\n",
       "60        wiki_ngram_question_median_score    0.2336\n",
       "59               wiki_ngram_answer_score_3    0.2336\n",
       "38                 wiki_question_min_score    0.2336\n",
       "61          wiki_ngram_question_mean_score    0.2336\n",
       "62           wiki_ngram_question_min_score    0.2336\n",
       "63             wiki_ngram_question_score_1    0.2336\n",
       "56             wiki_ngram_answer_min_score    0.2336\n",
       "55            wiki_ngram_answer_mean_score    0.2336\n",
       "54          wiki_ngram_answer_median_score    0.2336\n",
       "50          ck_12_ngram_question_min_score    0.2336\n",
       "37                wiki_question_mean_score    0.2336\n",
       "36              wiki_question_median_score    0.2336\n",
       "40                   wiki_question_score_2    0.2336\n",
       "41                   wiki_question_score_3    0.2336\n",
       "48       ck_12_ngram_question_median_score    0.2336\n",
       "64             wiki_ngram_question_score_2    0.2336\n",
       "49         ck_12_ngram_question_mean_score    0.2336\n",
       "29                  ck_12_question_score_3    0.2336\n",
       "53            ck_12_ngram_question_score_3    0.2336\n",
       "28                  ck_12_question_score_2    0.2336\n",
       "27                  ck_12_question_score_1    0.2336\n",
       "                                       ...       ...\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf = []\n",
    "for f in benchmark_features:\n",
    "    accucary = (results[f] == results.correct).mean()\n",
    "    bf.append((f, accucary)) \n",
    "    \n",
    "bf = pd.DataFrame(bf, columns=['feature', 'accuracy'])\n",
    "bf.sort('accuracy', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_f1 = list(train.apply(lambda x:'%s' % (x['question']),axis=1))\n",
    "train_f2 = list(train.apply(lambda x:'%s' % (x['answer']),axis=1))\n",
    "train_f3 = list(train.apply(lambda x:'%s' % (x['type']),axis=1))\n",
    "\n",
    "tfv1 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 2), max_df=1.0, min_df=1)\n",
    "train_f1 = tfv1.fit_transform(train_f1)\n",
    "\n",
    "tfv2 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f2 = tfv2.fit_transform(train_f2)\n",
    "\n",
    "tfv3 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f3 = tfv3.fit_transform(train_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w2v = np.column_stack((np.vstack(train.word2vecQuestion), \n",
    "                     np.vstack(train.word2vecAnswer),\n",
    "                     train.word2vecCosine))\n",
    "\n",
    "X = sparse.hstack((X_w2v, train_f1, train_f2, train_f3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = (train.label == 'true').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.665064106667\n",
      "1 0.657302613333\n",
      "2 0.684780373333\n",
      "3 0.677547946667\n",
      "4 0.66137088\n",
      "5 0.682840746667\n",
      "6 0.679188053333\n",
      "7 0.67444736\n",
      "8 0.687162453333\n",
      "9 0.67910272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.67488072533333343, 0.0097147205101174184)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import randomized_svd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.random_projection import GaussianRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = sparse.hstack((train_f1, train_f2))\n",
    "f3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def svd(X, K):\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    _, _, Vt = randomized_svd(X, n_components=K)\n",
    "    X_red = X.dot(Vt.T)\n",
    "    X_red = normalizer.fit_transform(X_red)\n",
    "    return Vt, normalizer, X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_svd(X, Vt, normalizer):\n",
    "    X_red = X.dot(Vt.T)\n",
    "    X_red = normalizer.transform(X_red)\n",
    "    return X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, f12_lsa = svd(f3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2 = sparse.hstack((X_w2v, train_f1, train_f2, train_f3, f12_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.665908906667\n",
      "1 0.660366933333\n",
      "2 0.677654613333\n",
      "3 0.6459136\n",
      "4 0.668356693333\n",
      "5 0.654816853333\n",
      "6 0.663981226667\n",
      "7 0.680082773333\n",
      "8 0.6553152\n",
      "9 0.659414613333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66318114133333339, 0.0099102097107178558)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_2, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_analyzer(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ck12_wiki_a = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "train_ck12_wiki_ans_docs = tf_ck12_wiki_a.fit_transform(train.ck_12_answer_names)\n",
    "\n",
    "tf_ck12_wiki_q = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "train_ck12_wiki_q_docs = tf_ck12_wiki_q.fit_transform(train.ck_12_question_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_3 = sparse.hstack((X_w2v, train_f1, train_f2, train_f3, train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6610752\n",
      "1 0.673678933333\n",
      "2 0.67387136\n",
      "3 0.693143466667\n",
      "4 0.687525546667\n",
      "5 0.663442773333\n",
      "6 0.674038186667\n",
      "7 0.6738944\n",
      "8 0.664942933333\n",
      "9 0.6731008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.67387136000000003, 0.0095431860244120301)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_3, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_4 = sparse.hstack((train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.621911893333\n",
      "1 0.629597866667\n",
      "2 0.651472213333\n",
      "3 0.62739584\n",
      "4 0.64610944\n",
      "5 0.629339306667\n",
      "6 0.644045226667\n",
      "7 0.629289813333\n",
      "8 0.61450624\n",
      "9 0.620079786667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6313747626666667, 0.011448613946852457)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_4, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck12_doc_features = sparse.hstack([train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs])\n",
    "ck12_Vt, ck12_norm, ck12_doc_lsa = svd(ck12_doc_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.637835946667\n",
      "1 0.628809386667\n",
      "2 0.6250176\n",
      "3 0.630808746667\n",
      "4 0.648206506667\n",
      "5 0.641179733333\n",
      "6 0.617064533333\n",
      "7 0.641742506667\n",
      "8 0.618552746667\n",
      "9 0.620676266667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.63098939733333337, 0.010286674028220841)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(ck12_doc_lsa, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck_12_num_feature_names = names('ck_12_question')[1:] + names('ck_12_answer')[1:] \n",
    "ck_12_num_features = train[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.61666816\n",
      "1 0.63328896\n",
      "2 0.632398506667\n",
      "3 0.609560746667\n",
      "4 0.624852906667\n",
      "5 0.622763093333\n",
      "6 0.623492693333\n",
      "7 0.63824512\n",
      "8 0.6222592\n",
      "9 0.61336704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6236896426666666, 0.0086001907230712753)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.609606826667\n",
      "1 0.637312853333\n",
      "2 0.608776533333\n",
      "3 0.60228736\n",
      "4 0.62870784\n",
      "5 0.619857493333\n",
      "6 0.612011946667\n",
      "7 0.615172693333\n",
      "8 0.62423168\n",
      "9 0.627469226667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.61854344533333339, 0.010309686616197565)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([X_w2v, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.719573333333\n",
      "1 0.717218986667\n",
      "2 0.73941376\n",
      "3 0.73192832\n",
      "4 0.725570133333\n",
      "5 0.728451413333\n",
      "6 0.719953493333\n",
      "7 0.728755626667\n",
      "8 0.7187456\n",
      "9 0.742381653333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.72719923200000003, 0.0083092323366117122)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck12_lucene = train[['ck12EbookBothQADocCount', 'ck12EbookBothQADocCountAMustHave', \n",
    "                    'ck12EbookKendallTauCorr', 'ck12EbookSpearmanCorr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.732593493333\n",
      "1 0.732473173333\n",
      "2 0.710340693333\n",
      "3 0.710674346667\n",
      "4 0.729996373333\n",
      "5 0.720894293333\n",
      "6 0.721151146667\n",
      "7 0.707158613333\n",
      "8 0.700814506667\n",
      "9 0.720866133333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.71869627733333341, 0.010551000648040187)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_6 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values, ck12_lucene.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_6, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = questions[questions.source == 'VALIDATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_f1 = list(validation.apply(lambda x:'%s' % (x['question']),axis=1))\n",
    "validation_f2 = list(validation.apply(lambda x:'%s' % (x['answer']),axis=1))\n",
    "\n",
    "validation_f1 = tfv1.transform(validation_f1)\n",
    "validation_f2 = tfv2.transform(validation_f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ck12_doc_features = sparse.hstack([train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs])\n",
    "# ck12_Vt, ck12_norm, ck12_doc_lsa = svd(ck12_doc_features, 100)\n",
    "\n",
    "val_ck12_wiki_ans_docs = tf_ck12_wiki_a.transform(validation.ck_12_answer_names)\n",
    "val_ck12_wiki_q_docs = tf_ck12_wiki_q.transform(validation.ck_12_question_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck12_doc_lsa_val = apply_svd(sparse.hstack([val_ck12_wiki_ans_docs, val_ck12_wiki_q_docs]), \n",
    "                             ck12_Vt, ck12_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_12_num_features_validation = validation[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=60, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=1000, max_features=60)\n",
    "clf.fit(X_5, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('rf_1000_60_tfidf_ck12_doc.bin', 'w') as f:\n",
    "    pickle.dump([clf, ck12_Vt, ck12_norm], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_5_val = sparse.hstack([validation_f1, validation_f2, ck12_doc_lsa_val, ck_12_num_features_validation.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_5_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>idx</th>\n",
       "      <th>questionId</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td> A</td>\n",
       "      <td> 0</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.199417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td> B</td>\n",
       "      <td> 1</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.194333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td> C</td>\n",
       "      <td> 2</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.192833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer  idx questionId     score\n",
       "10000      A    0     102501  0.199417\n",
       "10001      B    1     102501  0.194333\n",
       "10002      C    2     102501  0.192833\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(validation))\n",
    "\n",
    "val_index = pd.DataFrame({'idx': idx, 'questionId': validation.questionId, \n",
    "                          'answer': validation.answerLetter,\n",
    "                          'score': y_score})\n",
    "val_index.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for id, group in val_index.groupby('questionId'):\n",
    "    answer_idx = group.score.values.argmax()\n",
    "    answer = group.answer.values[answer_idx]\n",
    "    result.append((id, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(result, columns=['id', 'correctAnswer'])\n",
    "res.to_csv('/home/agrigorev/git-projects/allen-qa/validation_result.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
