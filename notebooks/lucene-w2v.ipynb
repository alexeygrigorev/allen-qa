{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs \n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = []\n",
    "with codecs.open('/home/agrigorev/git-projects/allen-qa/lucene-features-2.json', 'r', 'utf-8') as f:\n",
    "    for line in f:\n",
    "        dicts.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = pd.DataFrame(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_doc_features(docs):\n",
    "    top = docs[:3]\n",
    "    names = [d['title'] for d in top]\n",
    "    all_scores = [d['score'] for d in docs]\n",
    "    if not all_scores:\n",
    "        all_scores = [0]\n",
    "\n",
    "    top_scores = [d['score'] for d in top]\n",
    "    if not top_scores:\n",
    "        top_scores = [0]\n",
    "\n",
    "    median_score = np.median(all_scores)\n",
    "    mean_score = np.mean(all_scores)\n",
    "    min_score = np.min(all_scores)\n",
    "\n",
    "    score_1 = np.max(top_scores)\n",
    "    score_2 = np.median(top_scores)\n",
    "    score_3 = np.min(top_scores)\n",
    "\n",
    "    return pd.Series((names, median_score, mean_score, min_score, score_1, score_2, score_3))\n",
    "\n",
    "def names(pref):\n",
    "    res = ['names', 'median_score', 'mean_score', 'min_score', 'score_1', 'score_2', 'score_3']\n",
    "    return [pref + '_' + n for n in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'answer', u'answerLetter', u'ck12EbookAnswerResult', u'ck12EbookBothQADocCount', u'ck12EbookBothQADocCountAMustHave', u'ck12EbookKendallTauCorr', u'ck12EbookQuestionResult', u'ck12EbookSpearmanCorr', u'ck12WikiAnswerResult', u'ck12WikiBothQADocCount', u'ck12WikiBothQADocCountAMustHave', u'ck12WikiKendallTauCorr', u'ck12WikiQuestionResult', u'ck12WikiSpearmanCorr', u'label', u'ngramsAnswer', u'ngramsCk12EbookAnswerResult', u'ngramsCk12EbookBothQADocCount', u'ngramsCk12EbookBothQADocCountAMustHave', u'ngramsCk12EbookKendallTauCorr', u'ngramsCk12EbookQuestionResult', u'ngramsCk12EbookSpearmanCorr', u'ngramsCk12WikiAnswerResult', u'ngramsCk12WikiBothQADocCount', u'ngramsCk12WikiBothQADocCountAMustHave', u'ngramsCk12WikiKendallTauCorr', u'ngramsCk12WikiQuestionResult', u'ngramsCk12WikiSpearmanCorr', u'ngramsQuestion', u'question', u'questionId', u'rawAnswer', u'rawQuestion', u'source', u'type', u'word2vecAnswer', u'word2vecCosine', u'word2vecMissing', u'word2vecQuestion'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('ck_12_answer')] = questions.ck12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_question')] = questions.ck12EbookQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions[names('wiki_answer')] = questions.ck12WikiAnswerResult.apply(extract_doc_features)\n",
    "questions[names('wiki_question')] = questions.ck12WikiQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('ck_12_ngram_answer')] = questions.ngramsCk12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_ngram_question')] = questions.ngramsCk12EbookQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# something is wrong with ngram wiki, skipping it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions.word2vecAnswer = questions.word2vecAnswer.apply(lambda x: np.array(x).astype('float'))\n",
    "questions.word2vecQuestion = questions.word2vecQuestion.apply(lambda x: np.array(x).astype('float'))\n",
    "questions.word2vecCosine = questions.word2vecCosine.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NaNs_to_zeros(vec):\n",
    "    if np.isnan(vec).all():\n",
    "        return np.zeros_like(vec)\n",
    "    else:\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions.word2vecAnswer = questions.word2vecAnswer.apply(NaNs_to_zeros)\n",
    "questions.word2vecQuestion = questions.word2vecQuestion.apply(NaNs_to_zeros)\n",
    "questions.word2vecCosine[questions.word2vecCosine.isnull()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = questions[questions.source == 'TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_f1 = list(train.apply(lambda x:'%s' % (x['question']),axis=1))\n",
    "train_f2 = list(train.apply(lambda x:'%s' % (x['answer']),axis=1))\n",
    "train_f3 = list(train.apply(lambda x:'%s' % (x['type']),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfv1 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 2), max_df=1.0, min_df=1)\n",
    "train_f1 = tfv1.fit_transform(train_f1)\n",
    "\n",
    "tfv2 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f2 = tfv2.fit_transform(train_f2)\n",
    "\n",
    "tfv3 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f3 = tfv3.fit_transform(train_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w2v = np.column_stack((np.vstack(train.word2vecQuestion), \n",
    "                     np.vstack(train.word2vecAnswer),\n",
    "                     train.word2vecCosine))\n",
    "\n",
    "X = sparse.hstack((X_w2v, train_f1, train_f2, train_f3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = (train.label == 'true').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.665064106667\n",
      "1 0.657302613333\n",
      "2 0.684780373333\n",
      "3 0.677547946667\n",
      "4 0.66137088\n",
      "5 0.682840746667\n",
      "6 0.679188053333\n",
      "7 0.67444736\n",
      "8 0.687162453333\n",
      "9 0.67910272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.67488072533333343, 0.0097147205101174184)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import randomized_svd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.random_projection import GaussianRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = sparse.hstack((train_f1, train_f2))\n",
    "f3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def svd(X, K):\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    _, _, Vt = randomized_svd(X, n_components=K)\n",
    "    X_red = X.dot(Vt.T)\n",
    "    X_red = normalizer.fit_transform(X_red)\n",
    "    return Vt, normalizer, X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, f12_lsa = svd(f3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2 = sparse.hstack((X_w2v, train_f1, train_f2, train_f3, f12_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.665908906667\n",
      "1 0.660366933333\n",
      "2 0.677654613333\n",
      "3 0.6459136\n",
      "4 0.668356693333\n",
      "5 0.654816853333\n",
      "6 0.663981226667\n",
      "7 0.680082773333\n",
      "8 0.6553152\n",
      "9 0.659414613333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66318114133333339, 0.0099102097107178558)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_2, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_analyzer(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ck12_wiki_a = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "train_ck12_wiki_ans_docs = tf_ck12_wiki_a.fit_transform(train.ck_12_answer_names)\n",
    "\n",
    "tf_ck12_wiki_q = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "train_ck12_wiki_q_docs = tf_ck12_wiki_q.fit_transform(train.ck_12_question_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_3 = sparse.hstack((X_w2v, train_f1, train_f2, train_f3, train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6610752\n",
      "1 0.673678933333\n",
      "2 0.67387136\n",
      "3 0.693143466667\n",
      "4 0.687525546667\n",
      "5 0.663442773333\n",
      "6 0.674038186667\n",
      "7 0.6738944\n",
      "8 0.664942933333\n",
      "9 0.6731008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.67387136000000003, 0.0095431860244120301)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_3, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_4 = sparse.hstack((train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.621911893333\n",
      "1 0.629597866667\n",
      "2 0.651472213333\n",
      "3 0.62739584\n",
      "4 0.64610944\n",
      "5 0.629339306667\n",
      "6 0.644045226667\n",
      "7 0.629289813333\n",
      "8 0.61450624\n",
      "9 0.620079786667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6313747626666667, 0.011448613946852457)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_4, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck12_doc_features = sparse.hstack([train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs])\n",
    "_, _, ck12_doc_lsa = svd(ck12_doc_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.637835946667\n",
      "1 0.628809386667\n",
      "2 0.6250176\n",
      "3 0.630808746667\n",
      "4 0.648206506667\n",
      "5 0.641179733333\n",
      "6 0.617064533333\n",
      "7 0.641742506667\n",
      "8 0.618552746667\n",
      "9 0.620676266667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.63098939733333337, 0.010286674028220841)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(ck12_doc_lsa, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck_12_num_feature_names = names('ck_12_question')[1:] + names('ck_12_answer')[1:] \n",
    "ck_12_num_features = train[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.61666816\n",
      "1 0.63328896\n",
      "2 0.632398506667\n",
      "3 0.609560746667\n",
      "4 0.624852906667\n",
      "5 0.622763093333\n",
      "6 0.623492693333\n",
      "7 0.63824512\n",
      "8 0.6222592\n",
      "9 0.61336704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6236896426666666, 0.0086001907230712753)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.609606826667\n",
      "1 0.637312853333\n",
      "2 0.608776533333\n",
      "3 0.60228736\n",
      "4 0.62870784\n",
      "5 0.619857493333\n",
      "6 0.612011946667\n",
      "7 0.615172693333\n",
      "8 0.62423168\n",
      "9 0.627469226667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.61854344533333339, 0.010309686616197565)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([X_w2v, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.719573333333\n",
      "1 0.717218986667\n",
      "2 0.73941376\n",
      "3 0.73192832\n",
      "4 0.725570133333\n",
      "5 0.728451413333\n",
      "6 0.719953493333\n",
      "7 0.728755626667\n",
      "8 0.7187456\n",
      "9 0.742381653333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.72719923200000003, 0.0083092323366117122)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X_5, y, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    auc = roc_auc_score(ytest, clf.predict_proba(xtest)[:,0])\n",
    "    aucs.append(auc)\n",
    "    print i, auc\n",
    "\n",
    "np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
