{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs \n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = []\n",
    "with codecs.open('/home/agrigorev/git-projects/allen-qa/lucene-features-4-no-w2v.json', 'r', 'utf-8') as f:\n",
    "    for line in f:\n",
    "        #if line.contains('\"source\":\"VALIDATION\"'):\n",
    "        #    continue\n",
    "        dicts.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42528"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'answer', u'answerLetter', u'ck12EbookAnswerResult', u'ck12EbookBothQADoc', u'ck12EbookBothQADocAMustHave', u'ck12EbookBothQADocCount', u'ck12EbookBothQADocCountAMustHave', u'ck12EbookBothQAScores', u'ck12EbookBothQAScoresMustHave', u'ck12EbookQuestionResult', u'ck12WikiAnswerResult', u'ck12WikiBothQADoc', u'ck12WikiBothQADocAMustHave', u'ck12WikiBothQADocCount', u'ck12WikiBothQADocCountAMustHave', u'ck12WikiBothQAScores', u'ck12WikiBothQAScoresMustHave', u'ck12WikiQuestionResult', u'label', u'ngramsAnswer', u'ngramsCk12EbookAnswerResult', u'ngramsCk12EbookBothQADoc', u'ngramsCk12EbookBothQADocCount', u'ngramsCk12EbookBothQADocCountAMustHave', u'ngramsCk12EbookBothQADocMustHave', u'ngramsCk12EbookBothQAScores', u'ngramsCk12EbookBothQAScoresMustHave', u'ngramsCk12EbookQuestionResult', u'ngramsCk12WikiAnswerResult', u'ngramsCk12WikiBothQADoc', u'ngramsCk12WikiBothQADocCount', u'ngramsCk12WikiBothQADocCountAMustHave', u'ngramsCk12WikiBothQADocMustHave', u'ngramsCk12WikiBothQAScores', u'ngramsCk12WikiBothQAScoresMustHave', u'ngramsCk12WikiQuestionResult', u'ngramsQuestion', u'question', u'questionId', u'rawAnswer', u'rawQuestion', u'source', u'type', u'word2vecAnswer', u'word2vecCosine', u'word2vecMissing', u'word2vecQuestion'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.DataFrame(dicts)\n",
    "questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_doc_features(docs):\n",
    "    top = docs[:3]\n",
    "    names = [d['title'] for d in top]\n",
    "    all_scores = [d['score'] for d in docs]\n",
    "    if not all_scores:\n",
    "        all_scores = [0]\n",
    "\n",
    "    top_scores = [d['score'] for d in top]\n",
    "    if not top_scores:\n",
    "        top_scores = [0]\n",
    "\n",
    "    median_score = np.median(all_scores)\n",
    "    mean_score = np.mean(all_scores)\n",
    "    min_score = np.min(all_scores)\n",
    "\n",
    "    score_1 = np.max(top_scores)\n",
    "    score_2 = np.median(top_scores)\n",
    "    score_3 = np.min(top_scores)\n",
    "\n",
    "    return pd.Series((names, median_score, mean_score, min_score, score_1, score_2, score_3))\n",
    "\n",
    "def names(pref):\n",
    "    res = ['names', 'median_score', 'mean_score', 'min_score', 'score_1', 'score_2', 'score_3']\n",
    "    return [pref + '_' + n for n in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions[names('ck_12_answer')] = questions.ck12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_question')] = questions.ck12EbookQuestionResult.apply(extract_doc_features)\n",
    "\n",
    "questions[names('wiki_answer')] = questions.ck12WikiAnswerResult.apply(extract_doc_features)\n",
    "questions[names('wiki_question')] = questions.ck12WikiQuestionResult.apply(extract_doc_features)\n",
    "\n",
    "questions[names('ck_12_ngram_answer')] = questions.ngramsCk12EbookAnswerResult.apply(extract_doc_features)\n",
    "questions[names('ck_12_ngram_question')] = questions.ngramsCk12EbookQuestionResult.apply(extract_doc_features)\n",
    "\n",
    "questions[names('wiki_ngram_answer')] = questions.ngramsCk12WikiAnswerResult.apply(extract_doc_features)\n",
    "questions[names('wiki_ngram_question')] = questions.ngramsCk12WikiQuestionResult.apply(extract_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['word2vecAnswer' 'word2vecQuestion' 'word2vecCosine'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6949cc05eb72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquestions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word2vecAnswer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'word2vecQuestion'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'word2vecCosine'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'word2vecMissing'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, level, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels %s not contained in axis'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1624\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['word2vecAnswer' 'word2vecQuestion' 'word2vecCosine'] not contained in axis"
     ]
    }
   ],
   "source": [
    "questions.drop(['word2vecAnswer', 'word2vecQuestion', 'word2vecCosine', 'word2vecMissing'], inplace=1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    questions.word2vecAnswer = questions.word2vecAnswer.apply(lambda x: np.array(x).astype('float'))\n",
    "    questions.word2vecQuestion = questions.word2vecQuestion.apply(lambda x: np.array(x).astype('float'))\n",
    "    questions.word2vecCosine = questions.word2vecCosine.astype('float')\n",
    "\n",
    "    def NaNs_to_zeros(vec):\n",
    "        if np.isnan(vec).all():\n",
    "            return np.zeros_like(vec)\n",
    "        else:\n",
    "            return vec\n",
    "\n",
    "    questions.word2vecAnswer = questions.word2vecAnswer.apply(NaNs_to_zeros)\n",
    "    questions.word2vecQuestion = questions.word2vecQuestion.apply(NaNs_to_zeros)\n",
    "    questions.word2vecCosine[questions.word2vecCosine.isnull()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_features = [u'ck12EbookBothQAScores', u'ck12EbookBothQAScoresMustHave',\n",
    "                    u'ck12WikiBothQAScores', u'ck12WikiBothQAScoresMustHave',\n",
    "                    u'ngramsCk12EbookBothQAScores', u'ngramsCk12EbookBothQAScoresMustHave',\n",
    "                    u'ngramsCk12WikiBothQAScores', u'ngramsCk12WikiBothQAScoresMustHave']\n",
    "\n",
    "for f in score_features:\n",
    "    questions[f] = questions[f].apply(lambda x: np.array(x).astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_names(pref):\n",
    "    return ['%s_both_score_%d' % (pref, i) for i in range(1, 4)]\n",
    "\n",
    "def top_scores(scores):\n",
    "    return pd.Series(scores[:3])\n",
    "\n",
    "for f in score_features:\n",
    "    questions[score_names(f)] = questions[f].apply(top_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_boolean(series):\n",
    "    series = np.array(series)\n",
    "\n",
    "    res = np.zeros_like(series, dtype=int)    \n",
    "    for i, chunk in enumerate(chunks(series, 4)):\n",
    "        max = np.max(chunk)\n",
    "        max_ids, = np.where(chunk == max)\n",
    "        for id in max_ids:\n",
    "            res[4 * i + id] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ck12EbookBothQADocCount',\n",
       " u'ck12EbookBothQADocCountAMustHave',\n",
       " u'ck12WikiBothQADocCount',\n",
       " u'ck12WikiBothQADocCountAMustHave',\n",
       " u'ngramsCk12EbookBothQADocCount',\n",
       " u'ngramsCk12EbookBothQADocCountAMustHave',\n",
       " u'ngramsCk12WikiBothQADocCount',\n",
       " u'ngramsCk12WikiBothQADocCountAMustHave',\n",
       " 'ck_12_answer_median_score',\n",
       " 'ck_12_answer_mean_score',\n",
       " 'ck_12_answer_min_score',\n",
       " 'ck_12_answer_score_1',\n",
       " 'ck_12_answer_score_2',\n",
       " 'ck_12_answer_score_3',\n",
       " 'ck_12_question_median_score',\n",
       " 'ck_12_question_mean_score',\n",
       " 'ck_12_question_min_score',\n",
       " 'ck_12_question_score_1',\n",
       " 'ck_12_question_score_2',\n",
       " 'ck_12_question_score_3',\n",
       " 'wiki_answer_median_score',\n",
       " 'wiki_answer_mean_score',\n",
       " 'wiki_answer_min_score',\n",
       " 'wiki_answer_score_1',\n",
       " 'wiki_answer_score_2',\n",
       " 'wiki_answer_score_3',\n",
       " 'wiki_question_median_score',\n",
       " 'wiki_question_mean_score',\n",
       " 'wiki_question_min_score',\n",
       " 'wiki_question_score_1',\n",
       " 'wiki_question_score_2',\n",
       " 'wiki_question_score_3',\n",
       " 'ck_12_ngram_answer_median_score',\n",
       " 'ck_12_ngram_answer_mean_score',\n",
       " 'ck_12_ngram_answer_min_score',\n",
       " 'ck_12_ngram_answer_score_1',\n",
       " 'ck_12_ngram_answer_score_2',\n",
       " 'ck_12_ngram_answer_score_3',\n",
       " 'ck_12_ngram_question_median_score',\n",
       " 'ck_12_ngram_question_mean_score',\n",
       " 'ck_12_ngram_question_min_score',\n",
       " 'ck_12_ngram_question_score_1',\n",
       " 'ck_12_ngram_question_score_2',\n",
       " 'ck_12_ngram_question_score_3',\n",
       " 'wiki_ngram_answer_median_score',\n",
       " 'wiki_ngram_answer_mean_score',\n",
       " 'wiki_ngram_answer_min_score',\n",
       " 'wiki_ngram_answer_score_1',\n",
       " 'wiki_ngram_answer_score_2',\n",
       " 'wiki_ngram_answer_score_3',\n",
       " 'wiki_ngram_question_median_score',\n",
       " 'wiki_ngram_question_mean_score',\n",
       " 'wiki_ngram_question_min_score',\n",
       " 'wiki_ngram_question_score_1',\n",
       " 'wiki_ngram_question_score_2',\n",
       " 'wiki_ngram_question_score_3',\n",
       " u'ck12EbookBothQAScores_both_score_1',\n",
       " u'ck12EbookBothQAScores_both_score_2',\n",
       " u'ck12EbookBothQAScores_both_score_3',\n",
       " u'ck12EbookBothQAScoresMustHave_both_score_1',\n",
       " u'ck12EbookBothQAScoresMustHave_both_score_2',\n",
       " u'ck12EbookBothQAScoresMustHave_both_score_3',\n",
       " u'ck12WikiBothQAScores_both_score_1',\n",
       " u'ck12WikiBothQAScores_both_score_2',\n",
       " u'ck12WikiBothQAScores_both_score_3',\n",
       " u'ck12WikiBothQAScoresMustHave_both_score_1',\n",
       " u'ck12WikiBothQAScoresMustHave_both_score_2',\n",
       " u'ck12WikiBothQAScoresMustHave_both_score_3',\n",
       " u'ngramsCk12EbookBothQAScores_both_score_1',\n",
       " u'ngramsCk12EbookBothQAScores_both_score_2',\n",
       " u'ngramsCk12EbookBothQAScores_both_score_3',\n",
       " u'ngramsCk12EbookBothQAScoresMustHave_both_score_1',\n",
       " u'ngramsCk12EbookBothQAScoresMustHave_both_score_2',\n",
       " u'ngramsCk12EbookBothQAScoresMustHave_both_score_3',\n",
       " u'ngramsCk12WikiBothQAScores_both_score_1',\n",
       " u'ngramsCk12WikiBothQAScores_both_score_2',\n",
       " u'ngramsCk12WikiBothQAScores_both_score_3',\n",
       " u'ngramsCk12WikiBothQAScoresMustHave_both_score_1',\n",
       " u'ngramsCk12WikiBothQAScoresMustHave_both_score_2',\n",
       " u'ngramsCk12WikiBothQAScoresMustHave_both_score_3',\n",
       " 'ngramsCk12EbookBothQAScores_both_score_1_ismax']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = questions._get_numeric_data()\n",
    "benchmark_features = list(num.columns)\n",
    "benchmark_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in benchmark_features:\n",
    "    questions[f + '_ismax'] = to_boolean(questions[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = questions[questions.source == 'TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for id, group in train.groupby('questionId'):\n",
    "    row = {}\n",
    "    row['correct'] = (group.label == 'true').values.argmax()\n",
    "\n",
    "    for f in benchmark_features:\n",
    "        row[f] = group[f].values.argmax()\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>         ngramsCk12EbookBothQAScores_both_score_1</td>\n",
       "      <td> 0.3896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>         ngramsCk12EbookBothQAScores_both_score_2</td>\n",
       "      <td> 0.3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>               ck12EbookBothQAScores_both_score_2</td>\n",
       "      <td> 0.3788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td> ngramsCk12EbookBothQAScoresMustHave_both_score_1</td>\n",
       "      <td> 0.3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>               ck12EbookBothQAScores_both_score_1</td>\n",
       "      <td> 0.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td> ngramsCk12EbookBothQAScoresMustHave_both_score_2</td>\n",
       "      <td> 0.3732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>         ngramsCk12EbookBothQAScores_both_score_3</td>\n",
       "      <td> 0.3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>       ck12EbookBothQAScoresMustHave_both_score_1</td>\n",
       "      <td> 0.3704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>               ck12EbookBothQAScores_both_score_3</td>\n",
       "      <td> 0.3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td> ngramsCk12EbookBothQAScoresMustHave_both_score_3</td>\n",
       "      <td> 0.3616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>       ck12EbookBothQAScoresMustHave_both_score_2</td>\n",
       "      <td> 0.3508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>          ngramsCk12WikiBothQAScores_both_score_1</td>\n",
       "      <td> 0.3452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>       ck12EbookBothQAScoresMustHave_both_score_3</td>\n",
       "      <td> 0.3368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>  ngramsCk12WikiBothQAScoresMustHave_both_score_1</td>\n",
       "      <td> 0.3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>          ngramsCk12WikiBothQAScores_both_score_2</td>\n",
       "      <td> 0.3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>  ngramsCk12WikiBothQAScoresMustHave_both_score_2</td>\n",
       "      <td> 0.3304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>                ck12WikiBothQAScores_both_score_1</td>\n",
       "      <td> 0.3256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>          ngramsCk12WikiBothQAScores_both_score_3</td>\n",
       "      <td> 0.3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>        ck12WikiBothQAScoresMustHave_both_score_1</td>\n",
       "      <td> 0.3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>                ck12WikiBothQAScores_both_score_2</td>\n",
       "      <td> 0.3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>        ck12WikiBothQAScoresMustHave_both_score_2</td>\n",
       "      <td> 0.3196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>        ck12WikiBothQAScoresMustHave_both_score_3</td>\n",
       "      <td> 0.3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>  ngramsCk12WikiBothQAScoresMustHave_both_score_3</td>\n",
       "      <td> 0.3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>                ck12WikiBothQAScores_both_score_3</td>\n",
       "      <td> 0.3068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>                             ck_12_answer_score_3</td>\n",
       "      <td> 0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>           ngramsCk12EbookBothQADocCountAMustHave</td>\n",
       "      <td> 0.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>                             ck_12_answer_score_2</td>\n",
       "      <td> 0.2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>                 ck12EbookBothQADocCountAMustHave</td>\n",
       "      <td> 0.2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>                        ck_12_answer_median_score</td>\n",
       "      <td> 0.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>                           ck_12_answer_min_score</td>\n",
       "      <td> 0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>                          ck_12_answer_mean_score</td>\n",
       "      <td> 0.2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>            ngramsCk12WikiBothQADocCountAMustHave</td>\n",
       "      <td> 0.2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>                             ck_12_answer_score_1</td>\n",
       "      <td> 0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>                  ck12WikiBothQADocCountAMustHave</td>\n",
       "      <td> 0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>                            wiki_answer_min_score</td>\n",
       "      <td> 0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>                              wiki_answer_score_2</td>\n",
       "      <td> 0.2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>                              wiki_answer_score_1</td>\n",
       "      <td> 0.2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>                     ngramsCk12WikiBothQADocCount</td>\n",
       "      <td> 0.2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>                              wiki_answer_score_3</td>\n",
       "      <td> 0.2656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>                           wiki_answer_mean_score</td>\n",
       "      <td> 0.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>                         wiki_answer_median_score</td>\n",
       "      <td> 0.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>                          ck12EbookBothQADocCount</td>\n",
       "      <td> 0.2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>                           ck12WikiBothQADocCount</td>\n",
       "      <td> 0.2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>                    ngramsCk12EbookBothQADocCount</td>\n",
       "      <td> 0.2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>                       ck_12_ngram_answer_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>                 wiki_ngram_question_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>                        ck_12_question_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>                      ck_12_question_median_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>                     wiki_ngram_answer_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>                      wiki_ngram_answer_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>                        wiki_ngram_answer_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>                        wiki_ngram_answer_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>                        wiki_ngram_answer_score_3</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td>                                  word2vecMissing</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>                       ck_12_ngram_answer_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>                                   word2vecCosine</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>                   wiki_ngram_question_mean_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>                    wiki_ngram_question_min_score</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>                      wiki_ngram_question_score_1</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>                      wiki_ngram_question_score_2</td>\n",
       "      <td> 0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  accuracy\n",
       "70          ngramsCk12EbookBothQAScores_both_score_1    0.3896\n",
       "71          ngramsCk12EbookBothQAScores_both_score_2    0.3848\n",
       "59                ck12EbookBothQAScores_both_score_2    0.3788\n",
       "73  ngramsCk12EbookBothQAScoresMustHave_both_score_1    0.3772\n",
       "58                ck12EbookBothQAScores_both_score_1    0.3760\n",
       "74  ngramsCk12EbookBothQAScoresMustHave_both_score_2    0.3732\n",
       "72          ngramsCk12EbookBothQAScores_both_score_3    0.3724\n",
       "61        ck12EbookBothQAScoresMustHave_both_score_1    0.3704\n",
       "60                ck12EbookBothQAScores_both_score_3    0.3620\n",
       "75  ngramsCk12EbookBothQAScoresMustHave_both_score_3    0.3616\n",
       "62        ck12EbookBothQAScoresMustHave_both_score_2    0.3508\n",
       "76           ngramsCk12WikiBothQAScores_both_score_1    0.3452\n",
       "63        ck12EbookBothQAScoresMustHave_both_score_3    0.3368\n",
       "79   ngramsCk12WikiBothQAScoresMustHave_both_score_1    0.3364\n",
       "77           ngramsCk12WikiBothQAScores_both_score_2    0.3316\n",
       "80   ngramsCk12WikiBothQAScoresMustHave_both_score_2    0.3304\n",
       "64                 ck12WikiBothQAScores_both_score_1    0.3256\n",
       "78           ngramsCk12WikiBothQAScores_both_score_3    0.3236\n",
       "67         ck12WikiBothQAScoresMustHave_both_score_1    0.3232\n",
       "65                 ck12WikiBothQAScores_both_score_2    0.3232\n",
       "68         ck12WikiBothQAScoresMustHave_both_score_2    0.3196\n",
       "69         ck12WikiBothQAScoresMustHave_both_score_3    0.3172\n",
       "81   ngramsCk12WikiBothQAScoresMustHave_both_score_3    0.3144\n",
       "66                 ck12WikiBothQAScores_both_score_3    0.3068\n",
       "15                              ck_12_answer_score_3    0.2976\n",
       "5             ngramsCk12EbookBothQADocCountAMustHave    0.2864\n",
       "14                              ck_12_answer_score_2    0.2856\n",
       "1                   ck12EbookBothQADocCountAMustHave    0.2844\n",
       "10                         ck_12_answer_median_score    0.2800\n",
       "12                            ck_12_answer_min_score    0.2784\n",
       "11                           ck_12_answer_mean_score    0.2764\n",
       "7              ngramsCk12WikiBothQADocCountAMustHave    0.2760\n",
       "13                              ck_12_answer_score_1    0.2748\n",
       "3                    ck12WikiBothQADocCountAMustHave    0.2748\n",
       "24                             wiki_answer_min_score    0.2700\n",
       "26                               wiki_answer_score_2    0.2684\n",
       "25                               wiki_answer_score_1    0.2668\n",
       "6                       ngramsCk12WikiBothQADocCount    0.2664\n",
       "27                               wiki_answer_score_3    0.2656\n",
       "23                            wiki_answer_mean_score    0.2644\n",
       "22                          wiki_answer_median_score    0.2624\n",
       "0                            ck12EbookBothQADocCount    0.2620\n",
       "2                             ck12WikiBothQADocCount    0.2592\n",
       "4                      ngramsCk12EbookBothQADocCount    0.2584\n",
       "39                        ck_12_ngram_answer_score_3    0.2336\n",
       "52                  wiki_ngram_question_median_score    0.2336\n",
       "17                         ck_12_question_mean_score    0.2336\n",
       "16                       ck_12_question_median_score    0.2336\n",
       "47                      wiki_ngram_answer_mean_score    0.2336\n",
       "48                       wiki_ngram_answer_min_score    0.2336\n",
       "49                         wiki_ngram_answer_score_1    0.2336\n",
       "50                         wiki_ngram_answer_score_2    0.2336\n",
       "51                         wiki_ngram_answer_score_3    0.2336\n",
       "9                                    word2vecMissing    0.2336\n",
       "38                        ck_12_ngram_answer_score_2    0.2336\n",
       "8                                     word2vecCosine    0.2336\n",
       "53                    wiki_ngram_question_mean_score    0.2336\n",
       "54                     wiki_ngram_question_min_score    0.2336\n",
       "55                       wiki_ngram_question_score_1    0.2336\n",
       "56                       wiki_ngram_question_score_2    0.2336\n",
       "                                                 ...       ...\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf = []\n",
    "for f in benchmark_features:\n",
    "    accucary = (results[f] == results.correct).mean()\n",
    "    bf.append((f, accucary)) \n",
    "    \n",
    "bf = pd.DataFrame(bf, columns=['feature', 'accuracy'])\n",
    "bf.sort('accuracy', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3896"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_accuracy(y, y_score):\n",
    "    questions = chunks(zip(y, y_score),  4)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for chunk in questions:\n",
    "        y_chunk, y_score_chunk = zip(*chunk)\n",
    "        correct = correct + (np.argmax(y_chunk) == np.argmax(y_score_chunk))\n",
    "        total = total + 1\n",
    "    \n",
    "    return 1.0 * correct / total\n",
    "\n",
    "calc_accuracy(y, questions.ngramsCk12EbookBothQAScores_both_score_1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, n_iter=5, test_size=0.25):\n",
    "    if sparse.issparse(X):\n",
    "        X = X.tocsr()\n",
    "    n = len(y)\n",
    "    qidx = np.arange(n) / 4\n",
    "    qidx = qidx[::4]\n",
    "\n",
    "    split = cross_validation.ShuffleSplit(n=len(qidx), n_iter=n_iter, test_size=test_size)\n",
    "\n",
    "    for train, test in split:\n",
    "        train_qidx = qidx[train]\n",
    "        test_qidx = qidx[test]\n",
    "        \n",
    "        train_idx = np.repeat(train_qidx, 4) * 4 + np.arange(len(train_qidx) * 4) % 4\n",
    "        test_idx  = np.repeat(test_qidx, 4) * 4  + np.arange(len(test_qidx) * 4) % 4\n",
    "        \n",
    "        yield (X[train_idx], y[train_idx], X[test_idx], y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = (train.label == 'true').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_0 = train[best_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_features = bf[bf.accuracy >= 0.30].feature\n",
    "best_features = best_features.apply(lambda x: x + '_ismax').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304 0.555466666667\n",
      "0.28 0.537333333333\n",
      "0.2768 0.530933333333\n",
      "0.2336 0.495466666667\n",
      "0.3072 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28032000000000001, 0.026376231724793434)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = []\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_0, y):\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2641: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_f1 = list(train.apply(lambda x:'%s' % (x['question']),axis=1))\n",
    "train_f2 = list(train.apply(lambda x:'%s' % (x['answer']),axis=1))\n",
    "train_f3 = list(train.apply(lambda x:'%s' % (x['type']),axis=1))\n",
    "\n",
    "tfv1 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 2), max_df=1.0, min_df=1)\n",
    "train_f1 = tfv1.fit_transform(train_f1)\n",
    "\n",
    "tfv2 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f2 = tfv2.fit_transform(train_f2)\n",
    "\n",
    "tfv3 = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer=u'word', stop_words=None, \n",
    "                       token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1)\n",
    "train_f3 = tfv3.fit_transform(train_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_w2v = np.column_stack((np.vstack(train.word2vecQuestion), \n",
    "#                      np.vstack(train.word2vecAnswer),\n",
    "#                      train.word2vecCosine))\n",
    "\n",
    "# X = sparse.hstack((X_w2v, train_f1, train_f2, train_f3))\n",
    "X = sparse.hstack((train_f1, train_f2, train_f3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2976 0.552881066667\n",
      "0.2848 0.54693376\n",
      "0.3264 0.564781653333\n",
      "0.2864 0.54079104\n",
      "0.2976 0.555137706667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.29855999999999999, 0.014927236850803981)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = []\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X, y):\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import randomized_svd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25508)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_12 = sparse.hstack((train_f1, train_f2))\n",
    "X_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd(X, K):\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    _, _, Vt = randomized_svd(X, n_components=K)\n",
    "    X_red = X.dot(Vt.T)\n",
    "    X_red = normalizer.fit_transform(X_red)\n",
    "    return Vt, normalizer, X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_svd(X, Vt, normalizer):\n",
    "    X_red = X.dot(Vt.T)\n",
    "    X_red = normalizer.transform(X_red)\n",
    "    return X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, _, X_12_lsa = svd(X_12, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2 = sparse.hstack((train_f1, train_f2, train_f3, X_12_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2704 0.52239872\n",
      "0.3312 0.56574592\n",
      "0.288 0.549410133333\n",
      "0.2912 0.537565013333\n",
      "0.2608 0.510480213333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28832000000000002, 0.02418912152187426)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_2, y):\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_analyzer(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ck12_d = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "ck12_docs_train = tf_ck12_d.fit_transform(train.ck12EbookBothQADoc)\n",
    "\n",
    "tf_ck12_dmh = TfidfVectorizer(analyzer=identity_analyzer, min_df=1)\n",
    "ck12_docs_mh_train = tf_ck12_dmh.fit_transform(train.ck12EbookBothQADocAMustHave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_3 = sparse.hstack((ck12_docs_train, ck12_docs_mh_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.272 0.528690346667\n",
      "0.2944 0.54183296\n",
      "0.2928 0.526051413333\n",
      "0.3072 0.537538133333\n",
      "0.296 0.534621866667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.29247999999999996, 0.011421803710447823)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_3, y):\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck12_Vt, ck12_norm, ck12_doc_lsa = svd(X_3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2912 0.5165632\n",
      "0.2816 0.524692053333\n",
      "0.2784 0.526139733333\n",
      "0.2864 0.530528426667\n",
      "0.272 0.51839616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28192, 0.0065892032902316782)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(ck12_doc_lsa, y):\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck_12_num_feature_names = names('ck_12_question')[1:] + names('ck_12_answer')[1:] + \\\n",
    "        score_names(u'ck12EbookBothQAScores') + score_names(u'ck12EbookBothQAScoresMustHave')\n",
    "ck_12_num_features = train[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4112 0.587826773333\n",
      "0.3664 0.5839232\n",
      "0.3728 0.595456853333\n",
      "0.3776 0.5882432\n",
      "0.3792 0.593838506667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38144, 0.015532366207374847)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([ck_12_num_features.values])\n",
    "\n",
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_5, y):\n",
    "    clf = LogisticRegressionCV()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376 0.569581653333\n",
      "0.4208 0.596921173333\n",
      "0.3696 0.573149866667\n",
      "0.352 0.589038506667\n",
      "0.392 0.594828373333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38207999999999992, 0.023217097148437841)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = np.hstack([ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_5, y):\n",
    "    clf = LogisticRegressionCV()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2128 0.47862784\n",
      "0.24 0.49056896\n",
      "0.2 0.480704\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-2f0ec86c921e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1581\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m                       )\n\u001b[1;32m-> 1583\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1584\u001b[0m             for train, test in folds)\n\u001b[0;32m   1585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, copy, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n\u001b[0;32m    713\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                 penalty, dual, verbose, max_iter, tol, random_state)\n\u001b[0m\u001b[0;32m    715\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         epsilon)\n\u001b[0m\u001b[0;32m    917\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_5, y):\n",
    "    clf = LogisticRegressionCV(penalty='l1', solver='liblinear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck12_lucene = train[['ck12EbookBothQADocCount', 'ck12EbookBothQADocCountAMustHave', \n",
    "                    'ck12EbookKendallTauCorr', 'ck12EbookSpearmanCorr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3072 0.543762773333\n",
      "0.2912 0.540124586667\n",
      "0.272 0.54571776\n",
      "0.3248 0.543277653333\n",
      "0.2704 0.524720213333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.29311999999999999, 0.020822142060796713)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_6 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values, ck12_lucene.values])\n",
    "\n",
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_5, y):\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.7411747 ],\n",
       "       [  6.85592365],\n",
       "       [  6.7411747 ],\n",
       "       ..., \n",
       "       [  2.63126969],\n",
       "       [  0.        ],\n",
       "       [ 21.66536331]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368 0.554702933333\n",
      "0.3584 0.560657493333\n",
      "0.344 0.5491392\n",
      "0.3616 0.558532693333\n",
      "0.3888 0.55894016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36415999999999993, 0.014615279675736623)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_7 = train.ngramsCk12EbookBothQAScoresMustHave_both_score_1.values.reshape((-1, 1))\n",
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_7, y):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.3712 0.550682026667\n",
      "0.3792 0.560206933333\n",
      "0.368 0.552768426667\n",
      "0.3632 0.554533546667\n",
      "0.384 0.557558186667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.37311999999999995, 0.0075319054694014797)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_7 = train.ngramsCk12EbookBothQAScoresMustHave_both_score_1.values.reshape((-1, 1))\n",
    "accs = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in train_test_split(X_7, y):\n",
    "    #clf = LogisticRegression()\n",
    "    #clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_score = X_test[:, 0]\n",
    "    acc = calc_accuracy(y_test, y_score)\n",
    "    accs.append(acc)\n",
    "    print acc, roc_auc_score(y_test, y_score)\n",
    "\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = questions[questions.source == 'VALIDATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_f1 = list(validation.apply(lambda x:'%s' % (x['question']),axis=1))\n",
    "validation_f2 = list(validation.apply(lambda x:'%s' % (x['answer']),axis=1))\n",
    "\n",
    "validation_f1 = tfv1.transform(validation_f1)\n",
    "validation_f2 = tfv2.transform(validation_f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ck12_doc_features = sparse.hstack([train_ck12_wiki_ans_docs, train_ck12_wiki_q_docs])\n",
    "# ck12_Vt, ck12_norm, ck12_doc_lsa = svd(ck12_doc_features, 100)\n",
    "\n",
    "val_ck12_wiki_ans_docs = tf_ck12_wiki_a.transform(validation.ck_12_answer_names)\n",
    "val_ck12_wiki_q_docs = tf_ck12_wiki_q.transform(validation.ck_12_question_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck12_doc_lsa_val = apply_svd(sparse.hstack([val_ck12_wiki_ans_docs, val_ck12_wiki_q_docs]), \n",
    "                             ck12_Vt, ck12_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_12_num_features_validation = validation[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=60, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_5 = sparse.hstack([train_f1, train_f2, ck12_doc_lsa, ck_12_num_features.values])\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=1000, max_features=60)\n",
    "clf.fit(X_5, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('rf_1000_60_tfidf_ck12_doc.bin', 'w') as f:\n",
    "    pickle.dump([clf, ck12_Vt, ck12_norm], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_5_val = sparse.hstack([validation_f1, validation_f2, ck12_doc_lsa_val, ck_12_num_features_validation.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_0_val = validation[best_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV()\n",
    "clf.fit(X_0, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_12_num_features_val = validation[ck_12_num_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_0_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>idx</th>\n",
       "      <th>questionId</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td> A</td>\n",
       "      <td> 0</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.174482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td> B</td>\n",
       "      <td> 1</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.162006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td> C</td>\n",
       "      <td> 2</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.435921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td> D</td>\n",
       "      <td> 3</td>\n",
       "      <td> 102501</td>\n",
       "      <td> 0.197680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td> A</td>\n",
       "      <td> 4</td>\n",
       "      <td> 102502</td>\n",
       "      <td> 0.174482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td> B</td>\n",
       "      <td> 5</td>\n",
       "      <td> 102502</td>\n",
       "      <td> 0.199860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td> C</td>\n",
       "      <td> 6</td>\n",
       "      <td> 102502</td>\n",
       "      <td> 0.221377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td> D</td>\n",
       "      <td> 7</td>\n",
       "      <td> 102502</td>\n",
       "      <td> 0.341383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer  idx questionId     score\n",
       "10000      A    0     102501  0.174482\n",
       "10001      B    1     102501  0.162006\n",
       "10002      C    2     102501  0.435921\n",
       "10003      D    3     102501  0.197680\n",
       "10004      A    4     102502  0.174482\n",
       "10005      B    5     102502  0.199860\n",
       "10006      C    6     102502  0.221377\n",
       "10007      D    7     102502  0.341383\n",
       "\n",
       "[8 rows x 4 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(validation))\n",
    "\n",
    "val_index = pd.DataFrame({'idx': idx, 'questionId': validation.questionId, \n",
    "                          'answer': validation.answerLetter,\n",
    "                          'score': y_score})\n",
    "val_index.head(n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for id, group in val_index.groupby('questionId'):\n",
    "    answer_idx = group.score.values.argmax()\n",
    "    answer = group.answer.values[answer_idx]\n",
    "    result.append((id, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(result, columns=['id', 'correctAnswer'])\n",
    "res.to_csv('/home/agrigorev/git-projects/allen-qa/validation_result.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
